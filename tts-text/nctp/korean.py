# version 1.1 : version 1 written in Google Style

from typing import Match
import jamo
import re

from nctp.dictionary.kor_sDict import kor_ipa_dict
from nctp.dictionary.precompile import get_dict, get_regex_pattern
from nctp.dictionary.kor_sDict import \
    num_to_kor, big_dec, num_to_kor_native, unit_to_kor1, \
    eng_cons_to_jamo_batchim, eng_cons_to_jamo, eng_longv_to_jamo, \
    eng_vowel_to_jamo, alpha_to_han, jaeum_to_han

JAMO_LEADS = "".join([chr(_) for _ in range(0x1100, 0x1113)])
JAMO_VOWELS = "".join([chr(_) for _ in range(0x1161, 0x1176)])
JAMO_TAILS = "".join([chr(_) for _ in range(0x11A8, 0x11C3)])

JAMO = JAMO_LEADS + JAMO_VOWELS + JAMO_TAILS

KR_SYMBOLS = JAMO


def get_ipa_symbols(kor_ipa_dict):
    symbol_list = []
    for phn_info in kor_ipa_dict.values():
        ipa = phn_info["ipa"]
        if ipa not in symbol_list:
            symbol_list.append(ipa)
    return symbol_list


KR_IPA_SYMBOLS = get_ipa_symbols(kor_ipa_dict)
KR_IPA_MAP = kor_ipa_dict


def join_period(text):
    '''
    check if there is a puncuation mark at the end of the sentence.
    if not, add period.

    Args:
        text (str): text sentence

    Returns:
        perioded text (str): text sentence with period

    Examples:
        >>> join_period("Hello, world")
        "Hello, world."
        >>> join_period("Hello, world?.")
        "Hello, world?."
        >>> join_period("Hello, world..")
        "Hello, world.."
    '''
    # ì¤‘êµ­/ì¼ë³¸ì˜ ë¬¸ì¥ë¶€í˜¸ ëŒ€ì‘ (UPDATED 24.02.21)
    # #4ëŠ” ì¤‘êµ­ì–´ EOS
    # ì¶”ê°€ëœ ì´ëª¨ì§€ë“¤ì€ styletag end symbol ì„. (ë¬¸ì¥ ëì— ì´ê²ƒë“¤ì´ ì˜¤ëŠ” ê²½ìš° ë§¨ ë’¤ì— .ì´ í•œë²ˆ ë” ë¶™ê¸° ë•Œë¬¸)
    punctuation = ('!', '?', '.', '~', 'ï¼Ÿ','ï¼','ã€‚', "#4", "ğŸŠ", "ğŸ‹", 'ğŸ˜§', 'ğŸ˜‘', 'ğŸ˜„', 'ğŸ˜', 'ğŸ˜±', 'ğŸ˜¬', 'ğŸ™‰')
    if not text.endswith(punctuation):
        _perioded_text = text + '.'
    else:
        _perioded_text = text
    return _perioded_text


def remove_residual(text):
    """ ë¬¸ì¥ë¶€í˜¸ ì• ê³µë°±ì„ ì œê±°í•˜ê¸° ìœ„í•œ step
        ë¬¸ì¥ì˜ ë§ˆì§€ë§‰ì— ìœ„ì¹˜í•˜ëŠ” ë¬¸ì¥ë¶€í˜¸ì—ë„ ì ìš©í•˜ê¸° ìœ„í•´ì„œ,
        ì…ë ¥ í…ìŠ¤íŠ¸ ë§ˆì§€ë§‰ì— ì„ì‹œë¡œ `ï§¶`ë¥¼ ì¶”ê°€í•˜ì—¬ ì²˜ë¦¬ í›„ ì œê±°
        clean step ì¤‘ í•˜ë‚˜

    Args:
        text ([type]): ì…ë ¥ í…ìŠ¤íŠ¸
    Returns:
        [type]: [description]
    """
    punctuation = ('!', '?', '.', '~', ',', '-', '\'')
    special_punc = '|'.join(re.escape(a_punc) for a_punc in punctuation)
    # special_punc = [f'\{a_punc}' for a_punc in punctuation]
    residual_extract_pattern = re.compile(r'\s+([{}]+)([^\S]|[ï§¶])'.format(special_punc))

    threshold = 10
    for stopper in range(threshold):
        text_r = re.sub(residual_extract_pattern, lambda x : x.group(1) + x.group(2), text + 'ï§¶')
        text_r = text_r[:-1] if text_r.endswith('ï§¶') else text_r
        # ì²˜ë¦¬ ê²°ê³¼ê°€ ì²˜ë¦¬ ì´ì „ê³¼ ë™ì¼í•  ë•Œê¹Œì§€ ìˆ˜í–‰
        if text_r == text:
            break
        else:
            text = text_r
    return text

def remove_residual_2(text):
    """ ë¬¸ì¥ë¶€í˜¸ ì• ê³µë°±ì„ ì œê±°í•˜ê¸° ìœ„í•œ step
        ë¬¸ì¥ì˜ ë§ˆì§€ë§‰ì— ìœ„ì¹˜í•˜ëŠ” ë¬¸ì¥ë¶€í˜¸ì—ë„ ì ìš©í•˜ê¸° ìœ„í•´ì„œ,
        ì…ë ¥ í…ìŠ¤íŠ¸ ë§ˆì§€ë§‰ì— ì„ì‹œë¡œ `ğŸ—‘`ë¥¼ ì¶”ê°€í•˜ì—¬ ì²˜ë¦¬ í›„ ì œê±°
        clean step ì¤‘ í•˜ë‚˜

    Args:
        text ([type]): ì…ë ¥ í…ìŠ¤íŠ¸
    Returns:
        [type]: [description]
    """
    punctuation = ('!', '?', '.', '~', ',', '-', '\'', 'ã€‚', 'ã€', 'ï¼Ÿ', 'ï¼')
    special_punc = '|'.join(re.escape(a_punc) for a_punc in punctuation)
    # special_punc = [f'\{a_punc}' for a_punc in punctuation]
    residual_extract_pattern = re.compile(r'\s+([{}]+)([^\S]|[ğŸ—‘])'.format(special_punc))

    threshold = 10
    for stopper in range(threshold):
        text_r = re.sub(residual_extract_pattern, lambda x : x.group(1) + x.group(2), text + 'ğŸ—‘')
        text_r = text_r[:-1] if text_r.endswith('ğŸ—‘') else text_r
        # ì²˜ë¦¬ ê²°ê³¼ê°€ ì²˜ë¦¬ ì´ì „ê³¼ ë™ì¼í•  ë•Œê¹Œì§€ ìˆ˜í–‰
        if text_r == text:
            break
        else:
            text = text_r
    return text


def normalize_pronunciation(text):
    '''
    í•©ì„±í–ˆì„ ë•Œ ë°œìŒì´ ì–´ìƒ‰í•œ ë¶€ë¶„ë“¤ì„ ì ì ˆíˆ ì „ì²˜ë¦¬í•œë‹¤. (ì¦‰, model specificí•˜ë¯€ë¡œ ë°ì´í„° ì¦ê°€ë¡œ ë°œìŒì´ ê´œì°®ì•„ì§ˆ ê²½ìš° í•¨ìˆ˜ë¥¼ ì‚­ì œí•˜ë©°, ë°˜ëŒ€ë¡œ í•„ìš”ì‹œ ì¶”ê°€í•œë‹¤.)

    Args:
        text (str): text sentence ** ìŒìš´ ë³€í™˜ì„ ìëª¨ ë‹¨ìœ„ë¡œ ë¶„ì„í•˜ê¸° ë•Œë¬¸ì— í•œê¸€ ìëª¨ëŠ” ìŠ¤íŠ¸ë§ì—ì„œ ë‹¨ë…ìœ¼ë¡œ ì˜¤ì§€ ì•ŠëŠ”ë‹¤ê³  ê°€ì • (ã„±,ã„´,ã„·,ã…£,ã…—,ã…œ, etc), ì—ëŸ¬ëŠ” ì•ˆ ë‚¨

    Returns:
        text (str): normalized text

    Examples:
        >>> text = 'ê½ƒìì€ ë¨¹ì„ìˆ˜ë¡ ë§›ì—†ë‹¤.'
        >>> normalize_pronunciation(text)
        'ê¼°ë‹¢ì€ ë¨¹ì„ì‘¤ë¡ ë§ˆë¦ë‹¤.'
    '''
    # í˜•íƒœì†Œ ë¶„ì„ì´ í•„ìš”í•œ ê²ƒ(ì‹¤ì§ˆ vs í˜•ì‹, í•œìì–´, ë“±)ì€ ì•„ì‰¬ìš´ ëŒ€ë¡œ ë”•ì…”ë„ˆë¦¬ í˜•íƒœë¡œ ì²˜ë¦¬
    text = normalize_with_dictionary(text, 'pronounce_norm_pron', "chunks")

    # ë°ì´í„°ê°€ ë¶€ì¡±í•œ ê²¹ë°›ì¹¨ ë°œìŒì„ ì •ê·œì‹ìœ¼ë¡œ ì „ì²˜ë¦¬
    text = normalize_gyeopbatchim(text)

    # ã„¹ë¡œ ëë‚˜ëŠ” ì–´ê°„ ë°œìŒì„ ì •ê·œì‹ìœ¼ë¡œ ì „ì²˜ë¦¬
    text = normalize_rieul_batchim(text)

    return text


def normalize_gyeopbatchim(text):
    '''
    ê²¹ë°›ì¹¨ì„ í‘œì¤€ ë°œìŒë²•ì— ë§ê²Œ ì ì ˆí•˜ê²Œ ë°œìŒì‹œí‚¨ë‹¤. (í˜•íƒœì†Œ ë¶„ì„ì´ í•„ìš”í•œ ã„º, ã„¼, ã„» ë“±ì˜ ê²½ìš° ì œì™¸)

    Args:
        text (str): text sentence ** ìŒìš´ ë³€í™˜ì„ ìëª¨ ë‹¨ìœ„ë¡œ ë¶„ì„í•˜ê¸° ë•Œë¬¸ì— í•œê¸€ ìëª¨ëŠ” ìŠ¤íŠ¸ë§ì—ì„œ ë‹¨ë…ìœ¼ë¡œ ì˜¤ì§€ ì•ŠëŠ”ë‹¤ê³  ê°€ì • (ã„±,ã„´,ã„·,ã…£,ã…—,ã…œ, etc), ì—ëŸ¬ëŠ” ì•ˆ ë‚¨

    Returns:
        text (str): normalized text

    Examples:
        >>> text = 'ë„ˆë¬´ ì§‘ì¤‘í•´ì„œ ê°œê°€ íŒ”ì„ í•¥ëŠ”ì§€ë„ ëª°ëë‹¤.'
        >>> normalize_gyeopbatchim(text)
        'ë„ˆë¬´ ì§‘ì¤‘í•´ì„œ ê°œê°€ íŒ”ì„ í• ë¥¸ì§€ë„ ëª°ëë‹¤.'
    '''
    text = jamo.j2hcj(jamo.h2j(text))
    text = re.sub(r'ã„¾ã„´', 'ã„¹ã„¹', text)  # ã„¾ã„´ ì—°ì‡„ to ã„¹ã„¹ ì—°ì‡„: ã„´ì˜ ìœ ìŒí™” (í•¥ëŠ” --> í• ë¥¸) í‘œì¤€ ë°œìŒë²• ì œ20í•­
    text = re.sub(r'ã„¿(?!ã…‡|ã…)', 'ã…‚', text)  # ã„¿ ê²¹ë°›ì¹¨ to ã…‚ before ììŒ or ì–´ë§: ì¢…ì„±ì˜ ë°œìŒ (ìŠì†Œ --> ìì†Œ) ì œ11í•­
    text = re.sub(r'ã„¿ã…‡', 'ã„¹ã…', text)  # ã„¿ ê²¹ë°›ì¹¨ to ã„¹ã… before í˜•ì‹ í˜•íƒœì†Œ ëª¨ìŒ: ì¢…ì„±ì˜ ì—°ìŒ (ìŠì–´ë„ --> ì„í¼ë„) ì œ14í•­
    text = re.sub(r'ã„µ(ã„·|ã„±(?!ã…•|ã…£)|ã……|ã…ˆ)', lambda x: 'ã„´' + chr(ord(x.group(1)) + 1), text)  # ì–´ê°„ ã„µ ë’¤ ì´ˆì„±ì˜ ëœì†Œë¦¬í™”  (ì•‰ì --> ì•ˆì§œ) c.f. ì ‘ë¯¸ì‚¬ 'ê¸°'ê°€ ë”°ë¼ì˜¬ ë•Œ ì œì™¸ ì œ24í•­
    text = re.sub(r'ã„½(?!ã…‡)', 'ã„¹', text)  # ã„½ ê²¹ë°›ì¹¨ to ã„¹ before ììŒ or ì–´ë§: ì¢…ì„±ì˜ ë°œìŒ (ì™¸ê³¬ë§Œ --> ì™¸ê³¨ë§Œ) ì œ10í•­
    text = re.sub(r'ã„½ã…‡', 'ã„¹ã…†', text)  # ã„½ ê²¹ë°›ì¹¨ to ã„¹ã…† before í˜•ì‹ í˜•íƒœì†Œ ëª¨ìŒ: ì¢…ì„±ì˜ ì—°ìŒ (ì™¸ê³¬ìœ¼ë¡œë§Œ --> ì™¸ê³¨ì“°ë¡œë§Œ) ì œ14í•­
    text = re.sub(r'[ã„±-ã…ã…-ã…£]+', lambda x: jamo2han(x.group()), text)

    return text


def normalize_rieul_batchim(text):
    '''
    ã„¹ ì¢…ì„±ì˜ ê´€í˜•ì‚¬í˜•ì´ë‚˜ ì–´ë¯¸ë¥¼ í‘œì¤€ ë°œìŒë²•ì— ë§ê²Œ ì ì ˆíˆ ë°œìŒì‹œí‚¨ë‹¤.
    [í‘œì¤€ ë°œìŒë²• ì œ27í•­]
    1) ê´€í˜•ì‚¬í˜• '-(ìœ¼)ã„¹' ë’¤ì— ì—°ê²°ë˜ëŠ” 'ã„±,ã„·,ã…‚,ã……,ã…ˆ'ì€ ëœì†Œë¦¬ë¡œ ë°œìŒí•œë‹¤. ë‹¤ë§Œ, ëŠì–´ì„œ ë§í•  ì ì—ëŠ” ì˜ˆì‚¬ì†Œë¦¬ë¡œ ë°œìŒí•œë‹¤. ==> í˜•íƒœì†Œ ë¶„ì„ì„ ìš”í•´ì„œ '-í• ' í˜•íƒœë§Œ ìš°ì„  ì²˜ë¦¬
    2) '-(ìœ¼)ã„¹'ë¡œ ì‹œì‘ë˜ëŠ” ì–´ë¯¸ì˜ ê²½ìš°ì—ë„ ì´ì— ì¤€í•œë‹¤.

    Args:
        text (str): text sentence ** ìŒìš´ ë³€í™˜ì„ ìëª¨ ë‹¨ìœ„ë¡œ ë¶„ì„í•˜ê¸° ë•Œë¬¸ì— í•œê¸€ ìëª¨ëŠ” ìŠ¤íŠ¸ë§ì—ì„œ ë‹¨ë…ìœ¼ë¡œ ì˜¤ì§€ ì•ŠëŠ”ë‹¤ê³  ê°€ì • (ã„±,ã„´,ã„·,ã…£,ã…—,ã…œ, etc), ì—ëŸ¬ëŠ” ì•ˆ ë‚¨

    Returns:
        text (str): normalized text

    Examples:
        >>> text = 'ì‚¶ì´ ê·¸ëŒ€ë¥¼ ì†ì¼ì§€ë¼ë„.'
        >>> normalize_rieul_batchim(text)
        'ì‚¶ì´ ê·¸ëŒ€ë¥¼ ì†ì¼ì°Œë¼ë„.'
    '''
    text = jamo.j2hcj(jamo.h2j(text))
    # í•©ì„± ì‹œ '-í• 'ê³¼ ë’¤ì˜ ë‹¨ì–´ ì‚¬ì´ì— íœ´ì§€ê°€ ë„ˆë¬´ ê¸´ íƒ“ì— ëœì†Œë¦¬í™”ê°€ ë¶€ìì—°ìŠ¤ëŸ½ê²Œ ë“¤ë ¤ì„œ ìš°ì„  ì£¼ì„ ì²˜ë¦¬
    # text = re.sub(r'(?<=ã…ã…ã„¹ )(ã„·|ã„±|ã…‚|ã……|ã…ˆ)', lambda x: chr(ord(x.group(1)) + 1), text)  # ì œ27í•­ 1)ì—ì„œ ì•„ì‰¬ìš´ ëŒ€ë¡œ '-í• 'ë§Œì´ë¼ë„ ì¶”ê°€. ë‹¤ë§Œì„ ì°¸ê³ í•´ ìŠ¤í˜ì´ìŠ¤ í•˜ë‚˜ì¼ ë•Œë§Œ ëœì†Œë¦¬í™”
    pattern = re.compile(jamo.j2hcj(jamo.h2j('ã„¹(ê±¸|ë°–ì—|ì„¸ë¼|ìˆ˜ë¡|ì§€ì–¸ì •|ì§€ë¼ë„|ì§„ëŒ€)')))  # ì œ27í•­ 2)ì—ì„œ ì–¸ê¸‰ëœ ì–´ë¯¸ë“¤
    text = re.sub(pattern, lambda x: 'ã„¹' + chr(ord(x.group(1)[0]) + 1) + x.group(1)[1:], text)
    text = re.sub(r'[ã„±-ã…ã…-ã…£]+', lambda x: jamo2han(x.group()), text)

    return text


def drop_incompletes(text: str) -> str:
    '''
    ììŒ, ëª¨ìŒ ë¿ì¸ í•œê¸€ì„ ì œê±°í•œë‹¤.

    Args:
        text (str): text sentence

    Returns:
        text (str): normalized text

    Examples:
        >>> text = 'ã„±, ã„´ì„ ë³´ì‹œë©´ ìƒì„¸í•˜ê²Œ ì„¤ëª…ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ã…˜ã…£ã…—serious?'
        >>> drop_incompletes(text)
        ', ì„ ë³´ì‹œë©´ ìƒì„¸í•˜ê²Œ ì„¤ëª…ë˜ì–´ ìˆìŠµë‹ˆë‹¤. serious?'
    '''
    return re.sub(r'[ã…-ã…£ã„±-ã…]', "", text)


def normalize_character(text):
    '''
    ì˜ì–´ ììŒë§Œ ì˜¬ ê²½ìš°, ì•ŒíŒŒë²³ ì½ë“¯ì´ ì½ì–´ì¤€ë‹¤. ë‹¨ë…ìœ¼ë¡œ ì˜¨ ìëª¨ìŒì€ ì‚­ì œí•œë‹¤.

    Args:
        text (str): text sentence

    Returns:
        text (str): normalized text

    Examples:
        >>> text = 'HDDë¥¼ SSDë¡œ ë°”ê¾¸ì—ˆìŠµë‹ˆë‹¤.'
        >>> normalize_character(text)
        'ì—ì´ì¹˜ë””ë””ë¥¼ ì—ìŠ¤ì—ìŠ¤ë””ë¡œ ë°”ê¾¸ì—ˆìŠµë‹ˆë‹¤.'
    '''
    text = re.sub(r'[a-zA-Z]', lambda x: alpha_to_han[x.group().upper()], text)
    # text = re.sub(r'[ã„±-ã…]', lambda x: jaeum_to_han[x.group()], text)  # read jaeum to hangul
    return text


def normalize_english(text):
    '''
    normalizes english that are not in the dictionary (ëª¨ìŒì´ í•˜ë‚˜ë¼ë„ í¬í•¨ë˜ëŠ” ê²½ìš°ë§Œ ì •ê·œí™”. ììŒë§Œ ìˆìœ¼ë©´ normalize_characterì—ì„œ ì•ŒíŒŒë²³ ë°©ì‹ìœ¼ë¡œ ì •ê·œí™”)

    Args:
        text (str): text sentence

    Returns:
        text (str): normalized text

    Examples:
        >>> text = 'ëŒ“ MEANS í…Œì´í¬ A ë°± SEAT'
        >>> normalize_english(text)
        'ëŒ“ ë¯¼ìŠ¤ í…Œì´í¬ ì•„ ë°± ì‹¯'
    '''
    text = re.sub(r'[a-zA-Z]*[aeiouyAEIOUY]+[a-zA-Z]*', lambda x: jamo2han(eng2jamo(x.group())), text)

    return text


def eng2jamo(word):
    '''
    word ë‹¨ìœ„ ì˜ì–´ì˜ ë¯¸êµ­ì‹ ë°œìŒì„ ì¶”ì¸¡í•œ í›„, ì™¸ë˜ì–´ í‘œê¸°ë²•ì— ê°€ê¹ê²Œ ìëª¨ë¡œ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜
    ììŒê³¼ ëª¨ìŒìœ¼ë¡œ ë‚˜ëˆˆ í›„ forë¬¸ì„ ëŒë ¤ í•œê¸€ ìëª¨ë¡œ ì¹˜í™˜í•œë‹¤.

    Input :
        word(str) : word ë‹¨ìœ„ ì˜ì–´ (ì ì ˆí•œ ê²°ê³¼ëŠ” ì•ˆ ë‚˜ì˜¤ì§€ë§Œ ë¹„ì˜ì–´ ë¬¸ì ë° line ë‹¨ìœ„ë„ ì—ëŸ¬ ì—†ì´ ì²˜ë¦¬)

    Returns :
        word(str) : í•œê¸€ ìëª¨

    Examples:
        >>> word = 'marry'
        >>> eng2jamo(word)
        'ã…ã…ã„¹ã…£'
    '''
    # ìŒì†Œë¡œ ìª¼ê°œê¸° ì „ì— ê³µí†µì ì¸ ë¶€ë¶„ ì „ì²˜ë¦¬
    word = "@" + word.lower() + "%"  # '@' = BOW, '%' = EOW
    word = re.sub(r'([^aeiouwycg])\1(?!le%)', r'\1', word)  # delete duplicate consonants except for 1) cc and gg, and 2) when before le% (muddle --> muddle, shopping --> shoping, summer --> sumer, string --> string)
    word = re.sub(r'r(?=[^aeiouwy]|e%)', r'#', word)  # mark /r/ as silent r '#' when 1) comes before consonant, 2) takes the form of [aeiou]re%
    word = re.sub(r'sh(?=[aeiouwy])', r'sy', word)  # make 'sh' to /sy/ before vowel (ìƒ¤, ì‹œ, ì„€, ì…°, ìŠˆ, etc.)
    word = re.sub(r'@(w)([hr])', r'@\2\1', word)  # change 'wr', and 'wh' at BOW to 'rw' and 'hw' so that it sounds /r/ and /hw/ (white, write, wrap)
    word = re.sub(r'(?<!c)c(?=[eiy])', r's', word)  # make 'c', 'sc', to /s/ 'e' and 'i', and 'y', but not cc
    word = re.sub(r'(?<!g)g(?=[eiy])', r'j', word)  # make 'g', 'dg' to /j/ before 'e' and 'i', and 'y', but not gg
    phoneme_list = re.findall(r'(?<=[aeiouyw])[^aeiouyw]+e%|[aeiouyw]+|[^aeiouwy]+', word)  # silent e ('e'ë¡œ ëë‚˜ëŠ” ë‹¨ì–´)ëŠ” ì˜ì–´ì—ì„œ íŠ¹ë³„í•œ ì§€ìœ„ë¥¼ ê°€ì§€ë¯€ë¡œ ë”°ë¡œ ì²˜ë¦¬
    # print("phonemes in the given word: ", phoneme_list)
    kr_word = ''
    vowel = ''

    # ë”•ì…”ë„ˆë¦¬ì— ì—†ëŠ” ìŒì†Œì˜ ê²½ìš°, ììŒì€ 'ã…‡'ìœ¼ë¡œ, ëª¨ìŒì€ 'ã…¡'ë¡œ ë³€í™˜
    for phoneme in phoneme_list:
        if phoneme.endswith('le%'):  # [^aeiouyw]+le pattern (cuddle, middle, muscle, hustle, humble, apple, maple, tuple, etc.)
            consonant = re.search(r'.*(?=l)', phoneme).group()
            # ëª¨ìŒ ë³€í™˜
            if vowel in eng_vowel_to_jamo and consonant.startswith('#'):  # r controlled vowel, as in startle
                kr_word += eng_vowel_to_jamo[vowel][2]
            elif vowel in eng_vowel_to_jamo and len(consonant) == 2:  # ë‹¨ëª¨ìŒ as in apple
                kr_word += eng_vowel_to_jamo[vowel][3]
            elif vowel in eng_vowel_to_jamo:  # ì¥ëª¨ìŒ as in maple, fable
                kr_word += eng_vowel_to_jamo[vowel][1]
            else:
                kr_word += eng_longv_to_jamo.get(vowel, 'ã…¡')  # ê¸°íƒ€ ëª¨ìŒ, as in poodle
            # ììŒ ë³€í™˜
            if len(consonant) == 0:  # as in tale, pile
                kr_word += 'ã„¹'
            else:
                kr_word += eng_cons_to_jamo.get(consonant[0], 'ã…‡')
                if len(consonant) >= 2 and not (consonant[0] == 's' or consonant[0] == consonant[1]):  # as in humble, kindle, startle, but NOT fiddle, muscle
                    kr_word += eng_cons_to_jamo.get(consonant[1], 'ã…‡')  # 3ê°œ ì´ìƒì˜ ììŒêµ°ì€ ì˜ì–´ ìŒìš´ì—ì„œ ëª» ì˜¤ë¯€ë¡œ ë¬´ì‹œ
                kr_word += 'ã…¡ã„¹'
        elif phoneme.endswith('e%'):  # [^aeiouyw]+e pattern (change, fake, tape, etc.)
            consonant = re.search(r'[^aeiouyw]+', phoneme).group()
            # ëª¨ìŒ ë³€í™˜
            if consonant.startswith('#') and vowel in eng_vowel_to_jamo and len(consonant) >= 2:  # r controlled vowel, as in nurse, purse
                kr_word += eng_vowel_to_jamo[vowel][2]
            elif vowel in eng_vowel_to_jamo and len(consonant) >= 2:  # ë‹¨ëª¨ìŒ, as in sponge, judge, bridge, hence, resistance
                kr_word += eng_vowel_to_jamo[vowel][3]
            elif vowel in eng_vowel_to_jamo:  # ì¥ëª¨ìŒ
                kr_word += eng_vowel_to_jamo[vowel][1]
            else:  # ê¸°íƒ€ ëª¨ìŒ
                kr_word += eng_longv_to_jamo.get(vowel, 'ã…¡')
            # ììŒ ë³€í™˜
            if consonant == '#' :
                kr_word += 'ã…‡ã…“'
            elif consonant.endswith('j'):
                kr_word += eng_cons_to_jamo.get(consonant.split('j')[0], '')  # as in sponge, purge, bridge
                kr_word += 'ã…ˆã…£'
            else:
                kr_word += eng_cons_to_jamo.get(consonant[0], 'ã…‡')
                if len(consonant) >= 2:
                    kr_word += eng_cons_to_jamo.get(consonant[1], 'ã…‡')
                if consonant[-1] not in 'mnl' :
                    kr_word += 'ã…¡'
        elif phoneme[0] in 'aeiouwy' :  # ëª¨ìŒ ì €ì¥; ëª¨ìŒì˜ ë°œìŒ ë’¤ì˜ ììŒì— ì˜í•´ ê²°ì •ëœë‹¤
            if kr_word[-1] == 'ã…Š' and phoneme[0] == 'w' :  # as in matchwood (ì™¸ë˜ì–´ í‘œê¸°ë²• ì œ9í•­; ììŒ ë’¤ì— wê°€ ì˜¬ ë•Œì—” ë‘ ìŒì ˆë¡œ ê°ˆë¼ì ëŠ”ë‹¤)
                kr_word += 'ã…£ã…‡'
            elif kr_word[-1] not in 'ã…‡ã„±ã…‹ã…' and phoneme[0] == 'w' :  # as in swarm, twerk, swoln, swing (ìœ„ì™€ ë™ì¼, ë‹¨ g, h, këŠ” í•œ ìŒì ˆë¡œ ì ëŠ”ë‹¤.)
                kr_word += 'ã…¡ã…‡'
            vowel = phoneme
        else:  # ì¼ë°˜ì ì¸ ìëª¨ìŒ
            cons_list = re.findall(r'^@$|[st]ch|[gcs]{2}|dj|ght|[cs]hr?|g[nh]%|[ptg]h|@[gpk]n|[nc]k|ng|[td]s%|l[mn]|[^@]', phoneme)
            plosive_batchim = True  # ì™¸ë˜ì–´ í‘œê¸°ë²• ì œ1í•­ì˜ íŠ¹ì • ì¡°ê±´ì„ ë§Œì¡±í•  ê²½ìš° plosive sound(p, t, k)ë¥¼ ë°›ì¹¨ìœ¼ë¡œ ì ëŠ”ë‹¤
            # ëª¨ìŒ ë³€í™˜
            if vowel in eng_vowel_to_jamo:
                if cons_list[0] == 'ght' and vowel == 'i' :  # 'ight' pattern as in fright, fight, might
                    kr_word += 'ã…ã…‡ã…£'
                elif cons_list[0] == '#' :  # r controlled vowels; as in part, harp
                    kr_word += eng_vowel_to_jamo[vowel][2]
                elif cons_list[0] == '%' :  # ë‹¨ì–´ê°€ ëª¨ìŒìœ¼ë¡œ ëë‚  ë•Œ
                    kr_word += eng_vowel_to_jamo[vowel][0]
                else:  # ë‹¨ëª¨ìŒ
                    kr_word += eng_vowel_to_jamo[vowel][3]
            else:
                kr_word += eng_longv_to_jamo.get(vowel, "ã…¡")
                if cons_list == ['#', '%']:
                    kr_word += 'ã…‡ã…“'
            # ììŒ ë³€í™˜
            for curr, next in zip(cons_list, cons_list[1:] + ['^']):  # '^' == ììŒ ë’¤ì— ëª¨ìŒì´ ì˜¨ë‹¤ëŠ” í‘œì§€
                # print(curr, next)
                if curr in ['t', 'p', 'c', 'k', 'ck'] and next not in ['l', 'm', 'n', 'r', '^'] and plosive_batchim:  # ì™¸ë˜ì–´ í‘œê¸°ë²• ì œ1í•­
                    kr_word += eng_cons_to_jamo_batchim[curr]
                else:
                    kr_word += eng_cons_to_jamo.get(curr, 'ã…‡')
                    if curr in ['sh', 'ch', 'tch'] and next != '^' :
                        kr_word += 'ã…£'
                    elif curr == 'ng' and next == '^' :  # as in penguin
                        kr_word += 'ã„±'
                    elif curr == 'ng' and next == 'l' :  # as in hanglide
                        kr_word += 'ã„±ã…¡'
                    elif curr not in ['l', 'm', 'n', 'ng', 'gn%', 'lm', 'ln', '#'] and next != '^' :  # as in string, drizzle, but NOT tolkin, helm
                        kr_word += 'ã…¡'
                plosive_batchim = False  # ë¬´ì„± íŒŒì—´ìŒì´ ììŒêµ°ì˜ ì²«ë²ˆì§¸ ìœ„ì¹˜ì— ì˜¬ ë•Œë§Œ ì¢…ì„±ìœ¼ë¡œ ì ë„ë¡ í•œë‹¤
            vowel = ''

    # print(kr_word)

    return kr_word


def jamo2han(word):
    '''
    word ë‹¨ìœ„ì˜ ìëª¨ì˜ ì—°ì‡„(ã„±ã…ã„´)ë¥¼ ìŒì ˆ(ê°„)ë¡œ ë°”ê¾¸ëŠ” í•¨ìˆ˜, ë¹„ìëª¨ ë¬¸ìëŠ” ì‚­ì œ (normalize_english()ì—ì„œ ã„¹ã„¹ ë°œìŒì¸ 'l' ë° fjdksjkfl ì´ëŸ° ì‹ì˜ ëœë¤ ì¸í’‹ ëŒ€ë¹„ìš©)

    Input :
        word(str) : word ë‹¨ìœ„ ìëª¨ (ë¹„ìëª¨ëŠ” ì‚­ì œí•˜ê¸° ë•Œë¬¸ì—, line ë‹¨ìœ„ì—ì„œ ì—ëŸ¬ê°€ ë°œìƒí•˜ì§€ëŠ” ì•Šìœ¼ë‚˜ ì›í•˜ëŠ” ê²°ê³¼ëŠ” ë³´ì¥ë˜ì§€ ì•ŠìŒ)

    Returns :
        word(str) : word ë‹¨ìœ„ í•œê¸€

    Examples:
        >>> word = 'ã…‡ã…”ã„´ã…†ã…£ã……ã…—ã…ã…¡ã…Œã…¡'
        >>> jamo2han(word)
        'ì—”ì”¨ì†Œí”„íŠ¸'
        >>> word = 'ã„¹ã…ì–´ã…ì•„ì•„ì•™ã…‡ã…ã„´ã„´ã…•@@@@'
        >>> jamo2han(word)
        'ë¼ì•ˆë…€'
    '''
    if len(word) < 2:
        return ""
    elif not (0x3131 <= ord(word[0]) <= 0x314e and 0x314f <= ord(word[1]) <= 0x3163):  # ììŒ+ëª¨ìŒ íŒ¨í„´ì´ ì•„ë‹ ê²½ìš° ì‚­ì œ
        return jamo2han(word[1:])
    elif (len(word) == 3 and 0x3131 <= ord(word[2]) <= 0x314e) or (len(word) > 3 and 0x3131 <= ord(word[2]) <= 0x314e and 0x3131 <= ord(word[3]) <= 0x314e):
        return jamo.j2h(*word[0:3]) + jamo2han(word[3:])  # ì¢…ì„±ì´ ìˆëŠ” ê²½ìš° (ììŒ+ëª¨ìŒ+ììŒ)
    else:
        return jamo.j2h(*word[0:2]) + jamo2han(word[2:])  # ì¢…ì„±ì´ ì—†ëŠ” ê²½ìš° (ììŒ+ëª¨ìŒ)


__DICT_ACTIONS = {
    "key_only": {
        "type": "basic",
        "upper": False,
    },
    "chunks": {
        "type": "chunk",
        "upper": False,
    },
    "chunks_upper": {
        "type": "chunk",
        "upper": True,
    },
}


def normalize_with_dictionary(text: str, lang: str, act: str = 'chunks') -> str:
    '''
    Normalize if a specific character contains key of dictionary of given language.

    Args:
        text (str) : text sentence
        lang (dict): dictionary language (e.g. 'etc', 'english', 'universe')
        act  (str) : pattern ë°©ì‹ê³¼ ëŒ€ë¬¸ìë¡œ ì²˜ë¦¬ ì—¬ë¶€ë¥¼ êµ¬ë¶„í•˜ê¸° ìœ„í•œ keyì…ë‹ˆë‹¤.
                     should be in ["key_only", "chunks", "chunks_upper", for_service]

    Returns:
        text (str): normalized text

    Examples:
        >>> text = '1+1ì´ë‹¤.'
        >>> etc_dictionary = {'1+1':'ì›í”ŒëŸ¬ìŠ¤ì›'}
        >>> normalize_with_dictionary(text, 'etc', 'key_only')
        'ì›í”ŒëŸ¬ìŠ¤ì›ì´ë‹¤.'
    '''

    assert act in __DICT_ACTIONS, "Given act '{}' is not valid.".format(act)

    map = get_dict(lang, escaped=False)
    is_upper = __DICT_ACTIONS[act]["upper"]
    pat = get_regex_pattern(lang, __DICT_ACTIONS[act]["type"], ignorecase=is_upper)

    def convert_if_exists(m: Match) -> str:
        target = m.group()
        # ALL KEYS of original dictionary should be UPPERCASE in order to use `is_upper`
        if is_upper:
            target = target.upper()

        if target not in map:
            return target
        return map[target]

    if pat.search(text) is not None:
        return pat.sub(convert_if_exists, text)
    else:
        return text


def normalize_date(text):
    """ Detect date(yyyy[-/.]mm[-/.]dd) pattern in a sentence. Then, changing it to date pattern in english.

    Args:
        text ([str]): input text

    Returns:
        [str]: processed text
    """
    date_pattern = re.compile(r'([12]\d{3})[-/.]([1-9]|0[1-9]|1[0-2])[-/.](0[1-9]|[12]\d|3[01])')
    text = re.sub(date_pattern, lambda x: f'{x.group(1)}ë…„ {x.group(2)}ì›” {x.group(3)}ì¼', text)
    return text


def normalize_internet(text):
    """normalize internet address pattern.
       * ì…ë ¥ textì— ëŒ€í•œ ê°€ì • ì—†ìŒ.

    Args:
        text (str): text sentence

    Examples:
        >>> text = 'www.ncsoft.com'
        >>> res = normalize_internet(text)
        'www dot ncsoft dot com'
    """
    def insert_dot(group):
        p = re.compile(r'\.')
        group = re.sub(p, ' dot ', group)
        return group
    pattern = re.compile(r'[a-zA-Z]+\.[a-zA-Z]+')

    while pattern.findall(text):
        text = re.sub(pattern, lambda x: insert_dot(x.group()), text)

    return text


def normalize_numsequence(text):
    """normalize sequence of number pattern. It means to delete dash characters.
       * ì…ë ¥ textì— ëŒ€í•œ ê°€ì • ì—†ìŒ.

    Args:
        text (str): text sentence

    Examples:
        >>> text = '010-1111-1111'
        >>> res = normalize_numsequence(text)
        'ì˜ì¼ì˜ ì¼ì¼ì¼ì¼ ì¼ì¼ì¼ì¼'
    """
    def delete_dash(group, deco=' '):
        p = re.compile(r'\-')
        group = re.sub(p, deco, group)

        n_p = re.compile(r'[0-9]+')
        group = re.sub(n_p, lambda x: numeral(x.group(), type='normal'), group)

        return group

    # pattern = re.compile(r'[0-9]+\-[0-9]+\-[0-9]+')
    # text = re.sub(pattern, lambda x: delete_dash(x.group()), text)

    pattern = re.compile(r'([0-9]+\-){3,}([0-9]+)')
    text = re.sub(pattern, lambda x: delete_dash(x.group(), 'ë‹¤ì‹œ '), text)

    pattern = re.compile(r'([0-9]+\-){2,3}([0-9]+)')
    text = re.sub(pattern, lambda x: delete_dash(x.group(), ' '), text)

    return text


def normalize_range(text):
    """normalize the text including a range of numbers.
       * ì…ë ¥ textì— ëŒ€í•œ ê°€ì • ì—†ìŒ.

    Args:
        text (str): text sentence

    Examples:
        >>> text = '1~12ê°œì˜ ì½©'
        >>> res = normalize_range(text)
        'ì¼ì—ì„œ ì—´ë‘ê°œì˜ ì½©'
    """
    def insert_range(group):
        p = re.compile(r'\~')
        group = re.sub(p, 'ì—ì„œ ', group)

        n_p = re.compile(r'[0-9]+')
        group = re.sub(n_p, lambda x: numeral(x.group(), type='dec'), group)

        return group
    pattern = re.compile(r'[0-9]+\~[0-9]+')

    text = re.sub(pattern, lambda x: insert_range(x.group()), text)

    return text


def normalize_emoji(text):
    """normalize emoji pattern

    Args:
        text ([type]): [description]
    """
    emoji_pattern_dict = {
        # "unicode" : re.compile('(\u00a9|\u00ae|[\u2000-\u3300]|\ud83c[\ud000-\udfff]|\ud83d[\ud000-\udfff]|\ud83e[\ud000-\udfff])'),
        "str" : re.compile(r':\)|:-\)|:\(|:-\(|;\);-\)|:-O|8-|:P|:D|:\||:S|:\$|:@|8o\||\+o\(|\(H\)|\(C\)|\(\?\)|[\^\*\@\-\~\>]+[\.\,\_\^]+[\^\*\@\-\~\<]?')
    }
    for pattern in emoji_pattern_dict.values():
        text = re.sub(pattern, '', text)
    return text


def normalize_patterns(text):
    """normalize text with certain patterns.
       * ì…ë ¥ textì— ëŒ€í•œ ê°€ì • ì—†ìŒ.

    Args:
        text (str): text sentence

    Examples:
        >>> text = 'ë‚´ ì „í™”ë²ˆí˜¸ëŠ” 031-233-4455ì´ì•¼ 13~14ì‹œ ì‚¬ì´ì— ì „í™”í•´. ì´ë©”ì¼ ì£¼ì†ŒëŠ” nc@ncsoft.com'
        >>> res = normalize_patterns(text)
        'ë‚´ ì „í™”ë²ˆí˜¸ëŠ” 031 233 4455ì´ì•¼ 13ì—ì„œ 14ì‹œ ì‚¬ì´ì— ì „í™”í•´. ì´ë©”ì¼ ì£¼ì†ŒëŠ” nc@ncsoft dot com'
    """
    text = normalize_date(text)
    text = normalize_internet(text)
    text = normalize_numsequence(text)
    text = normalize_emoji(text)
    text = normalize_range(text)
    return text


# deprecated?
# def normalize_quote(text):
#     '''ëª¨ë“  ë”°ì˜´í‘œë¥¼ `ë¡œ í†µì¼'''
#     def fn(found_text):
#         from nltk import sent_tokenize  # NLTK doesn't along with multiprocessing

#         found_text = found_text.group()
#         unquoted_text = found_text[1:-1]

#         sentences = sent_tokenize(unquoted_text)
#         return " ".join(["'{}'".format(sent) for sent in sentences])

#     return re.sub(quote_checker, fn, text)


re_number = r"[+-]?\d+(?:,\d+)*(?:\.\d+)*"  # +-,.ëŠ” í•œ ë²ˆë§Œ ì¸ì‹, (,\d+)* : ì»´ë§ˆê°€ ì˜¤ëŠ” ìˆ«ìì˜ ë°˜ë³µ, (\.\d+)* : ì†Œìˆ˜ì  ë’¤ì˜ ìˆ«ì (,\d{3}ì´ ë˜ê²Œ í• ì§€ëŠ” ê³ ë¯¼)


def unit_to_pattern(unit_word_list):
    unit_word_list.sort(key=len, reverse=True)
    unit_word_pattern = "(" + "|".join(unit_word_list) + ")"
    return unit_word_pattern


# kr_unit_native_list : kr_unit_sino_list ë‚´ ë‹¨ìœ„ë¥¼ í¬í•¨í•˜ëŠ” ë‹¨ìœ„ ë¦¬ìŠ¤íŠ¸
#                       ê·¸ ì¤‘ ê³ ìœ ì–´ë¡œ ë°œìŒí•˜ëŠ” ë‹¨ìœ„ë“¤.
#                       ì˜ˆ ) 1ê°œì›” -> ì¼ê°œì›”
kr_unit_native_list = ["ê°œì›”", "ê°œë…„", "ë²ˆì§€"]
re_kr_unit_native = unit_to_pattern(kr_unit_native_list)

# kr_unit_sino_list : ê·¸ ì¤‘ í•œìì–´ë¡œ ë°œìŒí•˜ëŠ” ë‹¨ìœ„ë“¤.
#                       ì˜ˆ ) 1ì‹œ -> í•œ ì‹œ
kr_unit_sino_list = ["ì‹œ", "ëª…", "ê°€ì§€", "ì‚´", "ë§ˆë¦¬", "í¬ê¸°", "ì†¡ì´", "ìˆ˜", "í†¨", "í†µ", "ê°œ", "ë²Œ", "ì²™", "ì±„", "ë‹¤ë°œ",
                     "ê·¸ë£¨", "ìë£¨", "ì¤„", "ì¼¤ë ˆ", "ê·¸ë¦‡", "ì”", "ë§ˆë””", "ìƒì", "ì‚¬ëŒ", "ê³¡", "ë³‘", "íŒ",
                     "êµ°ë°", "ê¶Œ", "ë‹¢", "ëŒ€", "ë‘", "ëª¨", "ëª¨ê¸ˆ", "ë­‡", "ë°œ", "ë°œì§", "ë°©", "ë²ˆ", "ìˆ ", "ìŒˆ",
                     "ì›€ì¿°", "ì •", "ì§", "ì²©", "ì¶•", "ê±´", "ëŒ", "ë°°", "ê³³", "ì°¨ë¡€"]
re_kr_unit_sino = unit_to_pattern(kr_unit_sino_list)


def normalize_number(text):
    '''
    normalize a text with numbers
    * ì…ë ¥ textì— ëŒ€í•œ ê°€ì • ì—†ìŒ.

    Args:
        text (str): text sentence

    Returns:
        text (str): normalized text

    Examples:
        >>> text = 'ìµœê·¼ 1ë…„'
        >>> normalize_number(text)
        'ìµœê·¼ ì¼ë…„.'
    '''
    text = normalize_with_dictionary(text, 'unit', "chunks")
    text = re.sub(re_number + re_kr_unit_native,
                  lambda x: num2kor(x.group(), native=False), text)  # ìˆ«ìê°€ í•œìì–´ ë°©ì‹ìœ¼ë¡œ ì½ëŠ” ë‹¨ìœ„ì™€ í•¨ê»˜ ì¡´ì¬
    text = re.sub(re_number + re_kr_unit_sino,
                  lambda x: num2kor(x.group(), native=True), text)  # ìˆ«ìê°€ ê³ ìœ ì–´ ë°©ì‹ìœ¼ë¡œ ì½ëŠ” ë‹¨ìœ„ì™€ í•¨ê»˜ ì¡´ì¬
    text = re.sub(re_number,
                  lambda x: num2kor(x.group(), native=False), text)  # ìˆ«ìê°€ ë‹¨ë…ìœ¼ë¡œ ì¡´ì¬
    return text


def numtokor_sino(numb_list):
    ''' ì…ë ¥ìœ¼ë¡œ ë°›ì€ ìˆ«ìë¬¸ìì—´ë“¤ì„ í¬í•¨í•˜ëŠ” ë¦¬ìŠ¤íŠ¸ë¥¼ í•œìì–´(ì¼, ì´,...)ë¡œ ì„¸ëŠ” í•¨ìˆ˜
        * numb_listëŠ” stringì´ ì•„ë‹ˆë¼ list ì…ë‹ˆë‹¤.
        * numb_listì˜ ì›ì†Œë“¤ì€ 'í•œ ìë¦¬'ì˜ 'ìˆ«ì ë¬¸ìì—´'ì„ ê°€ì •í•˜ê³  ìˆìŠµë‹ˆë‹¤.

    Args:
        numb_list(list) : ìˆ«ìë¥¼ ì›ì†Œë¡œ í•˜ëŠ” list, ìˆ«ìëŠ” 1ìë¦¬ì”© ë‚˜ë‰˜ì–´ì§. ex) ['1','2','3']
    Returns:
        res(str) : ìˆ«ìë°œìŒ

    Examples:
        >>> numb_list = ['1','2','3']
        >>> numtokor_sino(numb_list)
        'ì¼ì´ì‚¼'
    '''
    res = ''
    len_numb = len(numb_list)
    dec_list = reversed(range(len_numb))
    for i, d in zip(dec_list, numb_list):
        if d == '1' :
            res += num_to_kor[str(10 ** i)]
        elif d == '0' :
            if len_numb == 1:  # 0 ë‹¨ë…ì¼ ë•Œ,
                res += num_to_kor[str(0)]
            pass
        else:
            res += num_to_kor[d]
            if i > 0:
                res += num_to_kor[str(10 ** i)]
    return res


def numtokor_native(numb_list, counter=False):
    ''' ê³ ìœ ì–´(í•˜ë‚˜, ë‘˜...)ë¡œ ìˆ«ìë¥¼ ì„¸ëŠ” í•¨ìˆ˜, 100 ë¯¸ë§Œì˜ ìˆ«ìë§Œ ê³ ìœ ì–´ë¡œ ì½ìŠµë‹ˆë‹¤.
        ê·¸ ì´ìƒì˜ ìˆ«ìëŠ” í•œìì–´ë¡œ ì½ìŠµë‹ˆë‹¤.
        * numb_listëŠ” stringì´ ì•„ë‹ˆë¼ list ì…ë‹ˆë‹¤.
        * numb_listì˜ ì›ì†Œë“¤ì€ 'í•œ ìë¦¬'ì˜ 'ìˆ«ì ë¬¸ìì—´'ì„ ê°€ì •í•˜ê³  ìˆìŠµë‹ˆë‹¤.
        * numb_listì˜ ìµœëŒ€ ê¸¸ì´ëŠ” 4ì…ë‹ˆë‹¤. ê·¸ ì´ìƒ ê¸¸ì´ë¥¼ ì…ë ¥í•  ê²½ìš° ë¹ˆ string ê²°ê³¼ë¥¼ ë¦¬í„´í•©ë‹ˆë‹¤.
          ì´ëŠ” numeral ë©”ì†Œë“œì—ì„œ ì…ë ¥ ìˆ«ìë¥¼ ìµœëŒ€ ê¸¸ì´ 4ë§Œí¼ ìª¼ê°œê³  numtokor_native ë©”ì†Œë“œë¥¼ ë°˜ë³µ ì‹¤í–‰í•˜ì—¬ ìˆ«ìë¥¼ ì²˜ë¦¬í•˜ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤.

    Args:
        numb_list(list) : ìˆ«ì ë¬¸ìì—´ì„ ì›ì†Œë¡œ í•˜ëŠ” list, ìˆ«ìëŠ” 1ìë¦¬ì”© ë‚˜ë‰˜ì–´ì§. ex) ['2','3']
        counter(bool) : ì› ë¬¸ìì—´ì— ë‹¨ìœ„ ì¡´ì¬ ìœ ë¬´, ê³ ìœ ì–´ ë°œìŒ êµ¬ë¶„ì— ì“°ì„.
    Returns:
        res(str) : ìˆ«ìë°œìŒ
    '''
    res = ''
    len_numb = len(numb_list)
    if len_numb > 2:  # ë‘ìë¦¬ ì´ˆê³¼í•˜ëŠ” ìˆ«ìì¸ ê²½ìš° í•œìì–´ë¡œ ì½ê¸°.
        res = numtokor_sino(numb_list)
    elif len_numb > 5:
        pass
    else:
        dec_list = reversed(range(len_numb))
        for i, d in zip(dec_list, numb_list):
            # ë‹¨ìœ„ê°€ ì—†ì„ ë•Œ, 'ì‰°í•˜ë‚˜' + ìŠ¤ë¬¼ì„¸ë²ˆì§¸ ì²˜ëŸ¼ ë‘ìë¦¬ìˆ«ì ì¤‘ 1ì˜ìë¦¬ ìˆ«ìê°€ 0ì´ ì•„ë‹Œê²½ìš°
            if (not counter) or ((i == 1) and (numb_list[-1] != '0')):
                selector = -1
            else:
                selector = 0
            if d == '0' and len_numb > 1:  # 1ì˜ìë¦¬ê°€ 0ì¸ ê²½ìš°ëŠ” 'ì˜'ìœ¼ë¡œ ë°œìŒí•˜ì§€ ì•ŠìŒ
                continue
            res += num_to_kor_native[str(int(d) * (10**i))][selector]

    return res


def numeral(numb, type, native=False, counter=False):
    ''' ì½ê¸° ë°©ë²•, ê³ ìœ ì–´/í•œìì–´ì— ë”°ë¼ ìˆ«ìë¥¼ í•œê¸€ë¡œ ë³€í™˜.
        24ìë¦¬ ì´ìƒì˜ ìˆ«ìëŠ” í•˜ë‚˜ì”© ì½ì–´ë‚˜ê°€ëŠ” (type = normal) ë°©ì‹ìœ¼ë¡œ ë³€í™˜.
        100 ë¯¸ë§Œì— í•´ë‹¹í•˜ëŠ” ìˆ˜ëŠ” nativeì— ë”°ë¼ ê³ ìœ ì–´/í•œìì–´ë¡œ ì½ìŒ.
        100 ì´ìƒì˜ ìˆ˜ëŠ” í•œìì–´ ì½ê¸° ë°©ì‹ì„ ë”°ë¥¸ë‹¤.
        * numbëŠ” 'ìˆ«ì(ì •ìˆ˜) ë¬¸ìì—´'ì„ì„ ê°€ì •í•©ë‹ˆë‹¤. ìˆ«ì ì™¸ ë¬¸ìê°€ í¬í•¨ë˜ë©´ ì²˜ë¦¬ê³¼ì • ì¤‘ ì—ëŸ¬ë¥¼ ë°œìƒì‹œí‚¬ ê²ƒì…ë‹ˆë‹¤.

    Args:
        numb(str) : str number
        type(str) : type of transformation
            1) 'dec' : ë§Œ, ì–µ, ì¡° ë‹¨ìœ„ë¥¼ ì‚¬ìš©í•˜ëŠ” í•œìì‹ ì½ê¸°ë°©ë²•
            2) 'normal' : ìˆ«ìë¥¼ í•˜ë‚˜ì”© ì½ì–´ ë‚˜ê°€ëŠ” ë°©ë²•
        native(bool) : ê³ ìœ ì–´ ì—¬ë¶€
        counter(bool) : ì› ë¬¸ìì—´ì— ë‹¨ìœ„ ì¡´ì¬ ìœ ë¬´, numtokor_nativeì—ì„œ ê³ ìœ ì–´ ë°œìŒ êµ¬ë¶„ì— ì“°ì„.

    Returns:
        res(str) : ìˆ«ìë°œìŒ
    '''
    numb_list = list(numb)
    len_numb = len(numb_list)
    # 24ìë¦¬ ì´ìƒì˜ ìˆ«ìëŠ” normal íƒ€ì…ìœ¼ë¡œ ë³€ê²½í•˜ì—¬ ì½ê¸°
    if len_numb > 24:
        type = 'normal'
    res = ''
    if type == 'dec' :
        quotient, remainder = divmod(len_numb, 4)
        quater_split = [remainder] + [4] * quotient  # ex) 134004 -> 13 / 4004 -> [2, 4]
        if quotient > 0:
            local_big_dec = big_dec[-quotient:]     # ex) 'ë§Œ' ë‹¨ìœ„
        for idx, i in enumerate(quater_split):
            if i:
                if (idx == len(quater_split) - 1) and len(numb_list[:i]) < 3 and native:
                    n = numb_list[:i]
                    res += numtokor_native(n, counter)  # 100ì˜ ìë¦¬ ë¯¸ë§Œì— í•´ë‹¹í•˜ëŠ” ìˆ˜ë§Œ ê³ ìœ ì–´ë¡œ ì½ëŠ”ë‹¤.
                else:
                    temp_res = numtokor_sino(numb_list[:i])
                    res += temp_res
                    if (temp_res == ''):
                        pass
                    elif (idx != len(quater_split) - 1):
                        res = res + local_big_dec[idx] + ' '
                numb_list = numb_list[i:]
        if res.endswith(' '):  # ë¬¸ìì˜ ë§ˆì§€ë§‰ì´ ê³µë€ìœ¼ë¡œ ë‚¨ì•„ìˆëŠ” ê²½ìš°ì— ê³µë€ ì‚­ì œ (ì˜ˆ: 'ì‚¬ì–µ ' -> 'ì‚¬ì–µ')
            res = res[:-1]

    elif type == 'normal' :
        for d in numb_list:
            res += num_to_kor[d]

    return res


def float_conversion(numb_str, res, native, counter=False):
    """ì†Œìˆ˜ì ì„ ê¸°ì¤€ìœ¼ë¡œ ì •ìˆ˜ë¶€, ì†Œìˆ˜ë¶€ë¥¼ ì²´í¬.
       ì†Œìˆ˜ì ì´ 3ê°œ ì´ìƒì¸ ê²½ìš°, ì •ìˆ˜ë¶€, ì†Œìˆ˜ë¶€1, ì†Œìˆ˜ë¶€2, ... ì†Œìˆ˜ë¶€n í˜•ì‹ìœ¼ë¡œ ë‚˜ëˆ ì§.
       ì •ìˆ˜ë¶€ëŠ” í•œìì–´ë¡œ ì½ê³  ì†Œìˆ˜ë¶€ëŠ” ê³ ìœ ì–´ë¡œ ì½ëŠ”ë‹¤.
       * numb_strì€ 'ìˆ«ì(ì†Œìˆ˜ ê°€ëŠ¥) ë¬¸ìì—´'ì„ ê°€ì •í•©ë‹ˆë‹¤. '.' ì™¸ì˜ ë¬¸ìê°€ í¬í•¨ë  ê²½ìš° ì—ëŸ¬ ë°œìƒ.

    Args:
        numb_str (string): ìˆ«ì ë¬¸ìì—´
        res (string): ì…ë ¥ ë¬¸ìì—´, ì…ë ¥ ë¬¸ìì—´ì— ê²°ê³¼ ë¬¸ìì—´ì„ ì¶”ê°€í•˜ì—¬ ìµœì¢… ì¶œë ¥í•¨.
        native(bool) : ê³ ìœ ì–´ ì—¬ë¶€
        counter(bool) : ì› ë¬¸ìì—´ì— ë‹¨ìœ„ ì¡´ì¬ ìœ ë¬´, ê³ ìœ ì–´ ë°œìŒ êµ¬ë¶„ì— ì“°ì„.

    Returns:
        res (string): ê²°ê³¼ ë¬¸ìì—´
    """
    # ì†Œìˆ˜ ì¸ì§€ í™•ì¸
    float_str_list = []
    check_float = numb_str.split('.')
    for i in range(len(check_float)):
        if i == 0:
            digit_str = check_float[i]
        else:
            float_str_list.append(check_float[i])

    # ì†Œìˆ˜ì¼ ë•ŒëŠ”, ê³ ìœ ì–´ë¡œ ì½ì§€ ì•ŠëŠ”ë‹¤.
    if len(float_str_list):
        if int(digit_str) == 0:
            digit_str = '0'
        res += numeral(str(int(digit_str)), type='dec', native=False)
        for float_str in float_str_list:
            res += 'ì©œ '
            res += numeral(float_str, type='normal', native=False)
    else:
        if int(digit_str) == 0:
            digit_str = '0'
        res += numeral(str(int(digit_str)), type='dec', native=native, counter=counter)

    return res


def num2kor(numb_str, native=False):
    ''''ìˆ«ì' í˜¹ì€ 'ìˆ«ì + ë‹¨ìœ„'ë¡œ ì´ë£¨ì–´ì§„ ë¬¸ìì—´ì„ í•œê¸€ ë°œìŒìœ¼ë¡œ ì²˜ë¦¬.
        +, - ê°€ ìˆ«ì ì•ì— ì¡´ì¬í•  ê²½ìš°, ê·¸ ê°œìˆ˜ë§Œí¼ 'í”ŒëŸ¬ìŠ¤','ë§ˆì´ë„ˆìŠ¤'ë¡œ ë³€í™˜.
        * numb_strì€ '(+, -) + ìˆ«ì + ë‹¨ìœ„ ë¬¸ìì—´'ì„ ê°€ì •í•©ë‹ˆë‹¤. ìˆ«ìë§Œ ì¡´ì¬í•  ê²½ìš° ì—ëŸ¬ ë°œìƒ.
        * ì—¬ê¸°ì„œ ë‹¨ìœ„ëŠ” ìµœëŒ€ 2ê¸€ìë¥¼ ì§€ë‹ˆê³ , ìˆ«ì ë°”ë¡œ ë’¤ì—ì˜¤ëŠ” ëª¨ë“  ë¬¸ìì—´ì„ ì˜ë¯¸í•©ë‹ˆë‹¤.
        * ë‹¨ìœ„ë¬¸ìì—´ì´ ë‹¨ìœ„ ë³€í™˜ ë”•ì…”ë„ˆë¦¬ unit_to_kor1ì— í¬í•¨ë˜ì§€ ì•ŠëŠ” ê²½ìš°ì—ëŠ” ë³€í™˜ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.

    Args:
        numb_str(str) : ì…ë ¥ë°›ì€ ë¬¸ìì—´, 'ìˆ«ì + ë‹¨ìœ„' í˜¹ì€ 'ìˆ«ì'
        native(bool) : ê³ ìœ ì–´ ì—¬ë¶€

    Returns:
        res (string): ê²°ê³¼ ë¬¸ìì—´
    '''
    res = ''
    counter = False
    # print(numb_str)
    # ë‹¨ìœ„ë¥¼ ì°¾ê³  ìˆ«ìì™€ ë‹¨ìœ„ ë¬¸ìì—´ë¡œ ë¶„ë¦¬
    count_filter = '[ê°€-í£a-zA-Z]{1,2}'  # ìµœëŒ€ ë‘ê¸€ì ë‹¨ìœ„ ì§€ì›
    count_str = re.search(count_filter, numb_str)
    if count_str is not None:
        counter = True
    numb_str = re.sub(count_filter, '', numb_str)

    # +, - ì²˜ë¦¬
    while 1:
        if numb_str.startswith("+"):
            res += 'í”ŒëŸ¬ìŠ¤ '
            numb_str = numb_str[1:]
        elif numb_str.startswith("-"):
            res += 'ë§ˆì´ë„ˆìŠ¤ '
            numb_str = numb_str[1:]
        else:
            break

    # ',' ì²˜ë¦¬
    numb_str = re.sub(',', '', numb_str)

    # ì†Œìˆ˜ ì—¬ë¶€ ì²´í¬, ë³€í™˜
    res = float_conversion(numb_str, res, native, counter)

    # ë‹¨ìœ„ ë¬¸ìì—´ì€ ìˆ«ì ë’¤ì— ì¶”ê°€
    if counter:
        res += count_str.group()

    return res


# NORMALIZE_DICT = {'patterns'       : {'f': normalize_patterns, 'a': None},
#                   'number'         : {'f': normalize_number, 'a': None},
#                   'etc_dictionary' : {'f': normalize_with_dictionary, 'a': etc_dict},
#                   'eng_dictionary' : {'f': normalize_with_dictionary, 'a': eng_dict},
#                   'english'        : {'f': normalize_english, 'a': None},
#                   'character'      : {'f': normalize_character, 'a': None},
#                   'pronunciation'  : {'f': normalize_pronunciation, 'a': None},
#                   'period'         : {'f': join_period, 'a': None}}

if __name__ == '__main__' :
    # print(numeral('12344320', type='dec'))
    # print(numeral('10008900', type='normal'))
    # print(num2kor('788990103.003323'))
    # print(num2kor('44,000,000,000'))
    # print(normalize_number('ì— ë¸Œë¼í…”ì‚¬ëŠ” ìœ„ì„±ë°©ì†¡ ì±„ë„ì˜ ìˆ«ìë¥¼ 98ë…„ë¶€í„° ì§€ê¸ˆë³´ë‹¤ 2ë°°ë‚˜ ëŠ˜ë¦´ ê³„íš.'))
    print(remove_residual("ã¿ã‚“ãªãŠç–²ã‚Œæ§˜ã§ã—ãŸ . å¸°ã‚Šã¾ã—ã‚‡ã†ã€ç§ãŸã¡ã®è¦å¡ã«  !"))